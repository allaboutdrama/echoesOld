<h1>Record a new sound</h1>

<%= form_for @sound do |f| %>
<% if @sound.errors.any? %>
<div class="error_messages">
  <h3>Form is invalid</h3>
  <ul>
    <% for message in @sound.errors.full_messages %>
    <li><%= message %></li>
    <% end %>
  </ul>
</div>

<% end %>
<!--  
<button onclick="startRecording(this);">record</button>
<button onclick="stopRecording(this);" disabled>stop</button>
-->  
<p id="output"></p>

<ul id="recordingslist"></ul>

<div class="form_field">
  <%= f.label :name %>
  <%= f.text_field :name %>
</div>

<div class="form_field">
  <%#= f.file_field :echo, id: "echo-file-field" %>
</div>

<%= f.hidden_field :latitude  %>
<%= f.hidden_field :longitude %>

<div class="form_field">
  <%= f.label :description%>
  <%= f.text_field :description %>
</div>

<div class="form_actions"><%= f.submit "Create Sound", {id: 'submit_new_sound'} %></div>
<% end %>

<%= link_to 'Back to Sounds', sounds_path %>


<script>
 // variables
 var leftchannel = [];
 var rightchannel = [];
 var recorder = null;
 var recording = false;
 var recordingLength = 0;
 var volume = null;
 var audioInput = null;
 var sampleRate = 44100;
 var audioContext = null;
 var context = null;
 var outputElement = document.getElementById('output');
 var outputString;

// feature detection 
if (!navigator.getUserMedia)
  navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia ||
navigator.mozGetUserMedia || navigator.msGetUserMedia;

if (navigator.getUserMedia){
  navigator.getUserMedia({audio:true}, success, function(e) {
    alert('Error capturing audio.');
  });
} else alert('getUserMedia not supported in this browser.');

// when key is down
window.onkeydown = function(e){

    // if R is pressed, we start recording
    if ( e.keyCode == 82 ){
      recording = true;
        // reset the buffers for the new recording
        leftchannel.length = rightchannel.length = 0;
        recordingLength = 0;
        outputElement.innerHTML = 'Recording now...';
    // if S is pressed, we stop the recording and package the WAV file
  } else if ( e.keyCode == 83 ){

        // we stop recording
        recording = false;
        
        outputElement.innerHTML = 'Preview your sound, add a name and description:';

        // we flat the left and right channels down
        var leftBuffer = mergeBuffers ( leftchannel, recordingLength );
        var rightBuffer = mergeBuffers ( rightchannel, recordingLength );
        // we interleave both channels together
        var interleaved = interleave ( leftBuffer, rightBuffer );
        
        // we create our wav file
        var buffer = new ArrayBuffer(44 + interleaved.length * 2);
        var view = new DataView(buffer);
        
        // RIFF chunk descriptor
        writeUTFBytes(view, 0, 'RIFF');
        view.setUint32(4, 44 + interleaved.length * 2, true);
        writeUTFBytes(view, 8, 'WAVE');
        // FMT sub-chunk
        writeUTFBytes(view, 12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        // stereo (2 channels)
        view.setUint16(22, 2, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * 4, true);
        view.setUint16(32, 4, true);
        view.setUint16(34, 16, true);
        // data sub-chunk
        writeUTFBytes(view, 36, 'data');
        view.setUint32(40, interleaved.length * 2, true);
        
        // write the PCM samples
        var lng = interleaved.length;
        var index = 44;
        var volume = 1;
        for (var i = 0; i < lng; i++){
          view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
          index += 2;
        }
        
        // our final binary blob
        window.blob = new Blob ( [ view ], { type : 'audio/wav' } );
        console.log("blob!");
        
        // let's save it locally
        var url = URL.createObjectURL(blob);
        var li = document.createElement('li');
        var au = document.createElement('audio');
        var hf = document.createElement('a');

        au.controls = true;
        au.src = url;
        hf.href = url;
        window.filename = new Date().toISOString() + '.wav';
        // hf.innerHTML = hf.download;
        li.appendChild(au);
        li.appendChild(hf);
        recordingslist.appendChild(li);
      }
    }

    function dataURLtoBlob(dataURL) {
      // Decode the dataURL    
      var binary = atob(dataURL.split(',')[1]);
      // Create 8-bit unsigned array
      var array = [];
      for(var i = 0; i < binary.length; i++) {
        array.push(binary.charCodeAt(i));
      }
      // Return our Blob object
      return new Blob([new Uint8Array(array)], {type: 'audio/wav'});
    }

    function interleave(leftChannel, rightChannel){
      var length = leftChannel.length + rightChannel.length;
      var result = new Float32Array(length);

      var inputIndex = 0;

      for (var index = 0; index < length; ){
        result[index++] = leftChannel[inputIndex];
        result[index++] = rightChannel[inputIndex];
        inputIndex++;
      }
      return result;
    }

    function mergeBuffers(channelBuffer, recordingLength){
      var result = new Float32Array(recordingLength);
      var offset = 0;
      var lng = channelBuffer.length;
      for (var i = 0; i < lng; i++){
        var buffer = channelBuffer[i];
        result.set(buffer, offset);
        offset += buffer.length;
      }
      return result;
    }

    function writeUTFBytes(view, offset, string){ 
      var lng = string.length;
      for (var i = 0; i < lng; i++){
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }

    function success(e){
    // creates the audio context
    audioContext = window.AudioContext || window.webkitAudioContext;
    context = new audioContext();

    // creates a gain node
    volume = context.createGain();

    // creates an audio node from the microphone incoming stream
    audioInput = context.createMediaStreamSource(e);

    // connect the stream to the gain node
    audioInput.connect(volume);

    /* From the spec: This value controls how frequently the audioprocess event is 
    dispatched and how many sample-frames need to be processed each call. 
    Lower values for buffer size will result in a lower (better) latency. 
    Higher values will be necessary to avoid audio breakup and glitches */
    var bufferSize = 2048;
    recorder = context.createJavaScriptNode(bufferSize, 2, 2);

    recorder.onaudioprocess = function(e){
      if (!recording) return;
      var left = e.inputBuffer.getChannelData (0);
      var right = e.inputBuffer.getChannelData (1);
        // we clone the samples
        leftchannel.push (new Float32Array (left));
        rightchannel.push (new Float32Array (right));
        recordingLength += bufferSize;
      }

    // we connect the recorder
    volume.connect (recorder);
    recorder.connect (context.destination); 
  }

  $('#submit_new_sound').click(function(ev) {
    ev.preventDefault();

    var formData = new FormData($('#new_sound')[0]);
    formData.append("echo", window.blob, window.filename);
    console.log(formData);
    $.ajax({
      url: '/sounds',
      type: 'POST',
      data: formData,
      processData: false,
      contentType: false
    });  
  })

  </script>


<%= javascript_tag do %>

  function updateSoundLocation(position){
  $('#sound_latitude').val(position.coords.latitude),
  $('#sound_longitude').val(position.coords.longitude)
}

function displayError(error) {
  var errors = { 
    1: 'Permission denied',
    2: 'Position unavailable',
    3: 'Request timeout'
  };
  alert("Error: " + errors[error.code]);
}


if (navigator.geolocation) {
  var timeoutVal = 10 * 1000 * 1000;
  navigator.geolocation.getCurrentPosition(
    updateSoundLocation,
    displayError,
    { enableHighAccuracy: true, timeout: timeoutVal, maximumAge: 0 }
    );
    }
  else {
    alert("Geolocation is not supported by this browser");
}

<% end %>