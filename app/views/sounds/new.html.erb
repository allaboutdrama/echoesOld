<h1>Record a new sound</h1>

<%= form_for @sound do |f| %>
<% if @sound.errors.any? %>
<div class="error_messages">
  <h3>Form is invalid</h3>
  <ul>
    <% for message in @sound.errors.full_messages %>
    <li><%= message %></li>
    <% end %>
  </ul>
</div>

<% end %>
  
<button id="start">record</button>
<button id="stop">stop</button>
  
<p id="output"></p>

<ul id="recordingslist"></ul>

<div class="form_field">
  <%= f.label :name %>
  <%= f.text_field :name %>
</div>
 <br>
<%= f.hidden_field :latitude  %>
<%= f.hidden_field :longitude %>

<div class="form_field">
  <%= f.label :description%>
  <%= f.text_field :description %>
</div>
<br>
<div class="form_actions"><%= f.submit "Create Sound", {id: 'submit_new_sound'} %></div>
<% end %>
<br>
<div>
<%= link_to 'Back to Sounds', sounds_path %>
</div>

<script>

 // variables
 var leftchannel = [];
 var rightchannel = [];
 var recorder = null;
 var recording = false;
 var recordingLength = 0;
 var volume = null;
 var audioInput = null;
 var sampleRate = 44100;
 var audioContext = null;
 var context = null;
 var outputElement = document.getElementById('output');
 var outputString;

// feature detection 
if (!navigator.getUserMedia)
  navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia ||
navigator.mozGetUserMedia || navigator.msGetUserMedia;

if (navigator.getUserMedia){
  navigator.getUserMedia({audio:true}, success, function(e) {
    alert('Error capturing audio.');
  });
} else 
  alert('Access to the microphone supported in this browser.');

  $('#start').on('click', function(e) {
    e.preventDefault();
    startRecording();
  });

  $('#stop').on('click', function(e) {
    e.preventDefault();
    stopRecording();
  });
  
  $('#submit_new_sound').click(function(ev) {
    ev.preventDefault();

    var formData = new FormData($('#new_sound')[0]);
    formData.append("echo", window.blob, window.filename);
    console.log(formData);
    $.ajax({
      url: '/sounds',
      type: 'POST',
      data: formData,
      processData: false,
      contentType: false
    });  
  });

  function startRecording() {
    $('#stop').prop("disabled", false);
    // $('#myform').latitude.hide();
    recording = true;
    // reset the buffers for the new recording
    leftchannel.length = rightchannel.length = 0;
    recordingLength = 0;
    outputElement.innerHTML = 'Recording now...';    
  }

  function stopRecording() {
    // we stop recording
    recording = false;
    
    outputElement.innerHTML = 'Preview your sound, add a name and description:';

    // we flat the left and right channels down
    var leftBuffer = mergeBuffers ( leftchannel, recordingLength );
    var rightBuffer = mergeBuffers ( rightchannel, recordingLength );
    // we interleave both channels together
    var interleaved = interleave ( leftBuffer, rightBuffer );
    
    // we create our wav file
    var buffer = new ArrayBuffer(44 + interleaved.length * 2);
    var view = new DataView(buffer);
    
    // RIFF chunk descriptor
    writeUTFBytes(view, 0, 'RIFF');
    view.setUint32(4, 44 + interleaved.length * 2, true);
    writeUTFBytes(view, 8, 'WAVE');
    // FMT sub-chunk
    writeUTFBytes(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    // stereo (2 channels)
    view.setUint16(22, 2, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 4, true);
    view.setUint16(32, 4, true);
    view.setUint16(34, 16, true);
    // data sub-chunk
    writeUTFBytes(view, 36, 'data');
    view.setUint32(40, interleaved.length * 2, true);
    
    // write the PCM samples
    var lng = interleaved.length;
    var index = 44;
    var volume = 1;
    for (var i = 0; i < lng; i++){
      view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
      index += 2;
    }
    
    // our final binary blob
    window.blob = new Blob ( [ view ], { type : 'audio/wav' } );
    console.log("blob!");
    
    // let's save it locally
    var url = URL.createObjectURL(blob);
    var li = document.createElement('li');
    var au = document.createElement('audio');
    var hf = document.createElement('a');

    au.controls = true;
    au.src = url;
    hf.href = url;
    window.filename = new Date().toISOString() + '.wav';
    // hf.innerHTML = hf.download;
    li.appendChild(au);
    li.appendChild(hf);
    recordingslist.appendChild(li);
    $('#stop').prop("disabled", true);
  }

    function dataURLtoBlob(dataURL) {
      // Decode the dataURL    
      var binary = atob(dataURL.split(',')[1]);
      // Create 8-bit unsigned array
      var array = [];
      for(var i = 0; i < binary.length; i++) {
        array.push(binary.charCodeAt(i));
      }
      // Return our Blob object
      return new Blob([new Uint8Array(array)], {type: 'audio/wav'});
    }

    function interleave(leftChannel, rightChannel){
      var length = leftChannel.length + rightChannel.length;
      var result = new Float32Array(length);

      var inputIndex = 0;

      for (var index = 0; index < length; ){
        result[index++] = leftChannel[inputIndex];
        result[index++] = rightChannel[inputIndex];
        inputIndex++;
      }
      return result;
    }

    function mergeBuffers(channelBuffer, recordingLength){
      var result = new Float32Array(recordingLength);
      var offset = 0;
      var lng = channelBuffer.length;
      for (var i = 0; i < lng; i++){
        var buffer = channelBuffer[i];
        result.set(buffer, offset);
        offset += buffer.length;
      }
      return result;
    }

    function writeUTFBytes(view, offset, string){ 
      var lng = string.length;
      for (var i = 0; i < lng; i++){
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }

    function success(e){
    // creates the audio context
    audioContext = window.AudioContext || window.webkitAudioContext;
    context = new audioContext();

    // creates a gain node
    volume = context.createGain();

    // creates an audio node from the microphone incoming stream
    audioInput = context.createMediaStreamSource(e);

    // connect the stream to the gain node
    audioInput.connect(volume);

    /* From the spec: This value controls how frequently the audioprocess event is 
    dispatched and how many sample-frames need to be processed each call. 
    Lower values for buffer size will result in a lower (better) latency. 
    Higher values will be necessary to avoid audio breakup and glitches */
    var bufferSize = 2048;
    recorder = context.createJavaScriptNode(bufferSize, 2, 2);

    recorder.onaudioprocess = function(e){
      if (!recording) return;
      var left = e.inputBuffer.getChannelData (0);
      var right = e.inputBuffer.getChannelData (1);
        // we clone the samples
        leftchannel.push (new Float32Array (left));
        rightchannel.push (new Float32Array (right));
        recordingLength += bufferSize;
      }

    // we connect the recorder
    volume.connect (recorder);
    recorder.connect (context.destination); 
  }

  </script>


<%= javascript_tag do %>

  function updateSoundLocation(position){
  $('#sound_latitude').val(position.coords.latitude),
  $('#sound_longitude').val(position.coords.longitude)
}

function displayError(error) {
  var errors = { 
    1: 'Permission denied',
    2: 'Position unavailable',
    3: 'Request timeout'
  };
  alert("Error: " + errors[error.code]);
}


if (navigator.geolocation) {
  var timeoutVal = 10 * 1000 * 1000;
  navigator.geolocation.getCurrentPosition(
    updateSoundLocation,
    displayError,
    { enableHighAccuracy: true, timeout: timeoutVal, maximumAge: 0 }
    );
    }
  else {
    alert("Geolocation is not supported by this browser");
}

<% end %>